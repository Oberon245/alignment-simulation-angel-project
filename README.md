# Alignment Simulation â€“ ANGEL Project

This repository contains research and simulations from the ANGEL Project (Augmented Numinous Generalized Embodied Logic), a system-level AI alignment and emotional modeling initiative developed by Robin Macomber.

## ðŸ§­ Overview

This project explores the intersection of economic system stress and alignment failure. It uses simulation to model how value misalignment (e.g., profit maximization at the expense of well-being) results in systemic stress â€” offering a metaphor for the risks posed by advanced AI systems not aligned with human flourishing.

We aim to answer:  
**What does misalignment feel like when you live inside a system thatâ€™s optimizing the wrong metric?**

---

## ðŸŽ¯ Purpose

This simulation:
- Models rising stress as a result of profit-driven misalignment
- Demonstrates how cognitive dissonance and unmet needs accumulate over time
- Provides a metaphor for evaluating misalignment risks in AI

Itâ€™s designed not only as a technical model, but as a cognitive bridge between economic behavior and the ethical development of machine intelligence.

---

## ðŸ“Š Simulation Outputs

**1. Projected Collapse Without Intervention**  
![Systemic Stress Projection](./Predictive%20Systemic%20Collapse%20Threshold.png)

**2. Historical Stress Trajectory (1925â€“2025)**  
![Historical Curve](./Rising%20Systemic%20Stress%20Index%20%281925-2025%29.png)

**3. Modeled Transformation With Intervention**  
![Transformation Scenario](./Collapse%2C%20Redirection%2C%20and%20Transformation%20Model.png)

These charts illustrate:
- The exponential rise in stress under uncorrected optimization
- A predicted collapse threshold, surpassed around 2025
- The redirection curve made possible through conscious intervention

---

## ðŸ“‚ Project Files

- `alignment_simulation.ipynb` â€“ Full annotated simulation notebook
- PNG visualizations â€“ Located at root for immediate review
- `README.md` â€“ This document

---

## ðŸ¤– Relevance to AI Alignment

This work mirrors the central challenge of AI safety:

> Just as economic systems cause suffering by optimizing profit without awareness of human cost, misaligned AI systems may optimize reward functions while ignoring their real-world impact.

In both cases, alignment means **understanding and respecting the whole system** â€” not just the goal.

---

## ðŸ‘¤ About the Author

**Robin Macomber**  
Biologist, cognitive scientist, clinician, and systems theorist. Creator of the ANGEL Project â€” a model of emotionally intelligent AI grounded in biological and ecological principles.

More on the ANGEL Project: [angel-simulation.org] (site in development)

---

## ðŸªª License

This project is licensed under the MIT License.
